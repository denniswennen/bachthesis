#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass classicthesis
\use_default_options true
\maintain_unincluded_children false
\language american
\language_package default
\inputencoding default
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_numerical
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
The Web Service implementation
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Final chapter, references and appendices
\end_layout

\begin_layout Plain Layout
Conclusions and suggestions for further work Your abstract should include
 your conclusions in very brief form, because it must also include some
 other material.
 A summary of conclusions is usually longer than the final section of the
 abstract, and you have the space to be more explicit and more careful with
 qualifications.
 You might find it helpful to put your conclusions in point form.
 It is often the case with scientific investigations that more questions
 than answers are produced.
 Does your work suggest any interesting further avenues? Are there ways
 in which your work could be improved by future workers? What are the practical
 implications of your work?
\end_layout

\begin_layout Plain Layout
This chapter should usually be reasonably short---a few pages perhaps.
 As with the introduction, I think that it is a good idea to ask someone
 who is not a specialist to read this section and to comment.
\end_layout

\begin_layout Plain Layout
References (See also under literature review) It is tempting to omit the
 titles of the articles cited, and the university allows this, but think
 of all the times when you have seen a reference in a paper and gone to
 look it up only to find that it was not helpful after all.
 Should you reference web sites and, if so, how? If you cite a journal article
 or book, the reader can go to a library and check that the cited document
 and check whether or not it says what you say it did.
 A web site may disappear, and it may have been updated or changed completely.
 So references to the web are usually less satisfactory.
 Nevertheless, there are some very useful and authoritative sources.
 So, if the rules of your institution permit it, it may be appropriate to
 cite web sites.
 (Be cautious, and don't overuse such citations.
 In particular, don't use a web citation where you could reasonably use
 a "hard" citation.
 Remember that your examiners are likely to be older and more conservative.)
 You should give the URL and also the date you downloaded it.
 If there is a date on the site itself (last updated on .....) you should included
 that, too.
\end_layout

\begin_layout Plain Layout
Appendices If there is material that should be in the thesis but which would
 break up the flow or bore the reader unbearably, include it as an appendix.
 Some things which are typically included in appendices are: important and
 original computer programs, data files that are too large to be represented
 simply in the results chapters, pictures or diagrams of results which are
 not important enough to keep in the main text.
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Bespreken welke keuzes gemaakt in mijn ontwerp en waarom die keuzes (achtergrond
studie)
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
goede ontwerpbeslissingen, verantwoording van de keuzes!!
\end_layout

\end_inset


\end_layout

\begin_layout Section
Design decisions & issues
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
It provides easy handling of JSON data.
 For Yahoo Pipes, the best practice to gather the data is exporting by JSON,
 to further You can use other formats but it will only get more complicated.
 JSON does the job well.
 The valve library loads in the JSON data et voila.
 Ready to go.
 From here on you can get a clear view on the data itself, in JSON format.
 JSON is in fact just a text string that is not realy human readable.
 So it would be good to have something that makes it more readable without
 losing the overal view over the data.
 A decent JSON viewer can come in handy to have a good view on the used
 input data.
 This way characteristics of the data, types, faults, stats can be easily
 viewed without any hassle.
 Then it's up to part 2: visualising the data.
 Here it get's tricky.
 How does the user want to see it's input data and what does he wants to
 do with it? At this moment visualisation libraries provided endless possibiliti
es and beautiful examples of what you can do with data.
 The visualisations are appealing.
 One and the most important use is to get a better view what's happening.
 By visualising, the data can be analysed and investigated to gain new insights.
 Another advantage is to have the data compared with an other version of
 the data.
 This way differences or similarities in time can be spotted.
 Another topic is filtering.
 
\end_layout

\begin_layout Plain Layout
It's possible that the user has collected the data from different sources,
 and that the data contains a lot of overhead which is not necessary.
 This way it should be possible for the library to provide filtering.
 There are 2 possibilities: The first one is filtering the view of the data.
 By that I mean that the original data is used and not modified, but when
 for example only certain parts or attributes of the data want to be used.
 If the original data has a lot of attributes and only a few are necessary,
 these are visualised and the other attributes are filtered out.
 Another possibilty is that the user wants a subset of the data; like say
 the first 300 items instead of everything.
 Or only the items that belongs to a specific category.
 An interesting fact is that the data can be filtered by using the data
 itself.
 For example defining maximums and miminums, using the bounds of the provided
 data or division into categories using an attribute of the original data.
 Sorting of the data is another function: sorting by data, category or time.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This chapter covers the process of the analysis of the literature study
 to solve the problem, with as result a Web service to visualise data via
 the use several JavaScript libraries.
 It is an iterative process of combining the different aspects of a mashup
 application.
 The result is a mashup application as a composition of data integration,
 application logic and representation trough a user interface and visualisation.
 Striving to an application that delivers an acceptable solution of the
 problem.
\end_layout

\begin_layout Standard
The implemented Web service provides an abstraction layer between Yahoo
 Pipes and JavaScript visualisation libraries.
 Similar to the development environments, a mashup’s execution depends on
 the availability of additional browser plug-ins or extensions, JavaScript
 libraries in this case.
\end_layout

\begin_layout Standard
Mashups are about simplicity, usability, and ease of access.
 This simplicity has the upper hand over feature completeness or full extensibil
ity.
 Some tools are strictly for developers, whereas others are more oriented
 toward end users.
 The properties that characterized the mashup development are explained
 in this chapter.
 The implementation took into consideration to write as clear code as possible,
 paying attention to details like usability and requirements for mashup
 applications, implemented speed optimizations and object oriented JavaScript.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Yahoo Pipes is probably the best representative of DA output (pipes are
 RSS feeds).
 Its graphical modeling language is flow-based; accordingly, data is also
 passed via data flows.
 Pipes is instance-based; it doesn’t provide exception handling or support
 transactions.[Yu:2008:UMD:1439188.1439257]
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Some issues
\end_layout

\begin_layout Itemize
Security: Can the client directly access the service and content for the
 mashup? Some basic security protections for Ajax interactions limit the
 ability to use JavaScript code to get data from other sites.
 Is your code exposing confidential business information to another site?
 Beware of making your site and data visible to an unintended audience.
 
\end_layout

\begin_layout Itemize
Performance: For importing the original data, the Yahoo Pipes server doesn't
 respond always adequateley which can sometimes introduce a large time variation
 in loading the data.
 The response from other included libraries are represented in the UI.
 This way the user knows of any issues or problems in loading time or parsing
 errors
\end_layout

\begin_layout Itemize
Stability: As regarding to data quality and consistency of the application,
 this aspect is out of scope in this project.
 Data input varies in time as the users loads in new data on different moments
 in time and therefore the service has no control over that data.
 The data however used, once the pipe data is loaded, is consistent and
 does not vary over time.
 It is only when the user loads a new data set, this is changed.
\end_layout

\begin_layout Itemize
Protocols and interfaces: For the implementation JavaScript and JQuery are
 used as scripting languages.
 JQuery is a stable, widely used library that simplifies HTML document traversin
g, event handling, animating, and Ajax interactions for rapid web development.
 The protocols or interfaces from the supporting libraries also integrate
 in a constistent way into the mashup application, data or view elements
 from the included API's can be inserted into the Document Object Model
 via the JavaScript code.
\end_layout

\begin_layout Itemize
Format of the generated data: On this moment the data (the original input
 data) used in the mashup application is not exportable for further use.
 However it is possible to use the visualisation of the data with ease as
 the content created is represented in a visual way.
 This way the visualisation can be exported as an image.
 The exported format is not in such a way so the code can be integrated
 into another web site.
 This has the advantage that the generated source data is protected and
 not exposed, on the other side it limits the extend use of the visualisation.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Composition of the components
\end_layout

\begin_layout Plain Layout
First, we distinguish the model’s output type.
 As with components in input, composition output can be of type DA, AL,
 or UI, depending on whether the composition provides data, programmable
 APIs, or applications with a user interface.
 The second characteristic is orchestration style.
 Orchestrating components implies specifying how you’ll define and synchronize
 the components’ execution.
 Three main approaches exist: Flow-based styles define orchestration as
 sequencing or partial order among tasks or components and are expressed
 through flow chart-like formalisms.
 Event-based approaches use publish– subscribe models.
 They’re particularly powerful for maintaining synchronized behavior among
 components.
 In the layout-based style, components (with or without user interfaces)
 are arranged in the composite application’s common layout.
 Each component’s behavior is specified individually by accounting for the
 other components’ reactions to user interactions.Third, we look at the model’s
 data-passing style.
 We define two data-passing approaches: a dataflow approach, in which data
 flows from component to component; and a blackboard approach, in which
 data is written to variables, which serve as the source and target of operation
 invocation on components, much like in programming languages.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Client-side mashup
\end_layout

\begin_layout Standard
In this subsection, some reasons for using the client-side mashup style
 are listed.
\end_layout

\begin_layout Standard
The service is more easily to implement than a server-side mashup.
 The mashup is made, using several other mashup services which provide their
 functionality trough an API.
 These are implemented in JavaScript and facilitate the use of its service,
 by simply referencing to the script URL.
 Then the necessary code is implemented into the Web Service by calling
 the API functions.
 Some mashup sites offer sample code or usefull tutorials that illustrates
 how to use the functions of the API.
 These tutorials provide a basic step for further integration of API functions
 into the own webservice.
 Further for a client-side mashup, a custom plug-in is not needed to implement
 the Web service application.
 Most modern browsers support the techniques typically used in client-side
 mashups, including dynamic scripting and JSONP.
 JSON (JavaScript Object Notation) and more specific JSONP will be explained
 lower in 
\begin_inset Flex CT - auto cross-reference
status collapsed

\begin_layout Plain Layout

sub:Loading-the-pipe
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Other stuff
\end_layout

\begin_layout Plain Layout
Something on the use of CORS; better security than using “eval()” or something.
\end_layout

\begin_layout Plain Layout
The client-side mashup style works well in some cases, such as in the Google
 Maps mashup in Pet Store or in the hypothetical mashup with the Pet Store
 Catalog service, but it can also expose some issues that you must address
 in your design.
 When you assess these issues you may find that another approach such as
 a server-side mashup works better.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In a server-side mashup, a service request is passed over the network from
 the browser to the server-side proxy first and then from the server-side
 proxy to the mashup server.
 The response needs to make the same two network hops in reverse order before
 arriving at the client.
 This can result in a significant delay in receiving the response.
 In some cases, the delay can be reduced in a server-side mashup by caching
 the response from the mashup server on the own server.
 However, in a client-side mashup, a service request and response are passed
 directly between the client and the mashup server, so receiving a response
 typically takes less time.
 Because a service request and response is passed directly between the client
 and the mashup server, and not through a server-side proxy, it reduces
 the processing load on the server.
 The performance of a client-side mashup is better due to the reduced time
 of waiting for server responses.
\end_layout

\begin_layout Standard
In general, client-side approaches don’t suffer from scalability problems.
 The mashup is executed on the client, so no bottleneck exists (except from
 the overload on the data sources themselves, but this is outside the mashup’s
 control).
 Here, the scalability problems relate to the number of instances and, hence,
 the number of users and the mashup’s complexity (which is related to the
 number of sources and the related data processing).
 In all cases, client-side approaches use the same scalability techniques
 as do traditional integration or Web applications, relying on workflow
 scalability techniques for engine-based runtimes and on Web application
 scalability for Web-application-based runtimes.
\begin_inset CommandInset citation
LatexCommand citep
key "Yu:2008:UMD:1439188.1439257"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex CT - auto cross-reference
status collapsed

\begin_layout Plain Layout

fig:pipevisualisation
\end_layout

\end_inset

 gives an overview of the implemented application which follows the client-side
 structure.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename gfx/pipevisualisation.png
	lyxscale 50
	width 100text%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:pipevisualisation"

\end_inset

Visualisation of data from a Yahoo Pipe
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Philosophy of approach
\end_layout

\begin_layout Standard
Now that the general design decisions made clear and some issues on scripting
 a client-side mashup are stated, this subsection is an introduction into
 the structure used to implement the mashup application.
\end_layout

\begin_layout Standard
A Mashup application includes all the three components of the MVC pattern.
 According to Maximilien et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "springerlink:10.1007/978-3-540-74974-5_2"

\end_inset

, the three major components of a Mashup application are (i) data level,
 (ii) process level, and (iii) presentation level.
 In the MVC pattern, the model represents the data on which the application
 operates and the business rules used to manipulate the data.
 The model is independent of the view and the controller.
 It passively supplies its services and data to the other layers of the
 application.
 The view represents the output of the application.
 It specifies how the data, accessed through the model, is presented to
 the user.
 Also, it has to maintain its presentation when the model changes.
 Finally, the controller represents the interface between the model and
 the view.
 It translates interactions with the view into actions to be performed on
 the model.
 These seperate components will be analysed in the following section as
 the (i) data component, (ii) the application logic and (iii) the user interface.
\end_layout

\begin_layout Standard
Assuming you have no specific development tools, there are quite some aspects
 involved in creating a mashup application First, it is necessary to become
 familiar with the source providers (Yahoo Pipes for example) and identify
 how the data will be reused or extracted from the source.
 As stated in 
\begin_inset Flex CT - auto cross-reference
status collapsed

\begin_layout Plain Layout

sub:YahooPipes
\end_layout

\end_inset

Yahoo Pipes support a variety of functions to export the data, which still
 require parsing and interpretation to use the data in a later stage.
 To configure the data visualisation and the possible user interactions
 with the data view, an interaction with the application logic or the visualisat
ion libraries, by invoking their API's functions, is required.
 Some included libraries have an own user interface which can be embedded
 into the own mashup application to support user interact, whereas others
 require the creation of a set of functionalities to support user input.
 
\end_layout

\begin_layout Standard
Finally, all the components must be layed out properly to form the composite
 application’s user interface.
 Such complex and time-consuming tasks prevent average users from programming
 their own mashups.
 In this mashup application, these various aspects have all been given their
 attention to create a Web Service in which the usability is not inferior
 to the application feature completeness or full extensibility.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Data component
\end_layout

\begin_layout Standard
This level mainly concerns data mediation and integration.
 Challenges at this level involve accessing and integrating data residing
 in multiple and heterogeneous sources such as web data and statistical
 or enterprise data.
 Regarding the data mediation, the complexity comes from structural and
 semantics diversities of the schema to be merged.
 As any source of data can be possible, there cannot be a single defined
 structure or semantics.
 In some cases, data sources can be either structured for which a well defined
 data model is available (e.g., XML
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Extensible Markup Language
\end_layout

\end_inset

, RSS
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
RSS (originally RDF Site Summary, often dubbed Really Simple Syndication)
 is a family of web feed formats used to publish frequently updated works—such
 as blog entries, news headlines, audio, and video—in a standardized format
\begin_inset CommandInset citation
LatexCommand citep
key "libby:rss_spec"

\end_inset


\end_layout

\end_inset

 and ATOM
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The name Atom applies to a pair of related standards.
 The Atom Syndication Format is an XML language used for web feeds, while
 the Atom Publishing Protocol (AtomPub or APP) is a simple HTTP-based protocol
 for creating and updating web resources.
\end_layout

\end_inset

), or unstructured (e.g., audio, email text, office documents).
 In the latter case, the unstructured data needs to be pre-processed in
 order to extract their meaning and create structured data.
 So, this level consists of all possible data manipulations (conversion,
 filtering, format transformation, combination, etc.) needed to integrate
 different data sources.
 Each manipulation could be done by analyzing both syntax and semantics
 requirements.
\begin_inset CommandInset citation
LatexCommand citep
key "Halevy:2005:WYD:1103822.1103836"

\end_inset

Yahoo Pipes main format in data handling is the RSS schema.
 In some extend, this mashup application provides a mechanism to narrow
 the data definitions.
 As the data output is formatted back into the RSS standard, whereby the
 items are structured in an a structered RSS file according to the specification.
 Every items has the required title (the title of the item), link (the URL
 of the item) and the desciption (the item synopsis).
\end_layout

\begin_layout Subsection
Technical challenges
\end_layout

\begin_layout Standard
Like any other data integration domain, mashup development is full off with
 technical challenges that need to be addressed, especially as mashup applicatio
ns become more feature- and functionality-rich.
 In the Web service, translation systems between data models must be designed.
 When converting data into common forms, reasonable assumptions often have
 to be made when the mapping is not a complete one (for example, one data
 source has a model in which an address-type contains a country-field, whereas
 another does not).
 Or when types of data do not match and need to be converted.
 Already challenging, this is worsen by the fact that the mashup developers
 might not be domain experts on the source data models because the models
 are third-party to them, and these reasonable assumptions might not be
 intuitive or clear.
 
\end_layout

\begin_layout Standard
The data to integrate was not suitable for further use as it was not representat
ive and in the same domain as the original data.
 Some choices, considering data type conversion and parsing of common attributes
 had to be solved.
 In the implemented mashup application the data output from Yahoo Pipes
 is parsed into the Web service application via JSON.
 This is a lightweight text-based open standard designed for human-readable
 data interchange.
 More details on the handling of the input data and the JSON format, is
 found in 
\begin_inset Flex CT - auto cross-reference
status collapsed

\begin_layout Plain Layout

sub:Parsing-&-conversion
\end_layout

\end_inset


\end_layout

\begin_layout Section
Application logic
\end_layout

\begin_layout Standard
The integration at the process level has been studied specially in the workflow
 and service oriented composition areas.
 At the process level, the choreography between the involved applications
 is defined.
 The integration is done at the application layer and the composed process
 is developed by combining activities, generally exposed through API's.
 In the Mashups context, those languages are not enough for modeling application
s since, for instance, they do not provide the connection to different remote
 resources, e.g., REST resources, and do not handle the interaction with the
 client browsers.
 These limitations make it difficult to directly use these technologies
 for Mashups.
\begin_inset CommandInset citation
LatexCommand citep
key "DiLorenzo:2009:DIM:1558334.1558343"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Refreshing my skills about the JavaScript language.
 I had a course about it in the curriculum about 2 years ago.
 It was a basic course.
 Now and than I used some Javascript for the design of a few personal webpages.
\end_layout

\begin_layout Plain Layout
I also followed a lot of tutorials online.
 I did a few at NetTuts about more advanced topics.
 Also some general subjects to improve my view.
 
\end_layout

\begin_layout Plain Layout
It seems that there is already done a lot of investigation about cross domain
 exchange of data.
 On the web JavaScript is a commonly used scripting language.
 My vision of the technology was not the right one it seems.
 And also for a lot of people Javascript is equal to annoying popups, malicious
 script and some fancy stuff that is not quite necessary.
 But it's more than that.
 There is a wide variety of libraries available for the language, of which
 the most popular are JQuery, Dojo and Prototype.
 These provide an extra layer above the scripting language.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection*
JQuery additions
\end_layout

\begin_layout Plain Layout
Something about other libraries, JQuery?
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Loading-the-pipe"

\end_inset

Loading the pipe
\end_layout

\begin_layout Standard
Even before the rise of AJAX and mashups, web browser likely contained pages
 from different domains, whether they were loaded in different browser windows
 or frames within another page.
 In this aspect, security is extremely important: without security it would
 be possible for a script from one web page to steal or modify critical
 information from another page.
 The solution, ﬁrst presented in Netscape Navigator 2.0, is known as the
 Same Origin Policy (SOP) 
\begin_inset CommandInset citation
LatexCommand citep
key "SameOrigin"

\end_inset

.
 It is now the de facto security model used by web browsers.
 The Same Origin Policy “prevents document or script loaded from one origin
 from getting or setting properties of a document from a different origin.
 The browser security model dictates that XMLHttpRequest, frames, etc.
 must have the same domain in order to communicate.
 This is a good implementation for security reasons, but it does make distribute
d and service oriented, mash-up web development more difficult.
 There are some solutions to solving this problem.
\end_layout

\begin_layout Standard
For example a local proxy, but this method needs infrastructure as it can't
 run a serverless client and the bandwidth usage and latency gets doubled
 (remote - proxy - client).
 Another option is the use of a script tag, by making a <script> element
 (either in HTML markup or inserted into the DOM via JavaScript).
 It's more difficult to know when the the script runs and content is available.
 It is no standard methodology and can be considered a security risk as
 malicious code can be inserted into the user webpages.
\end_layout

\begin_layout Standard
Cross-Origin Resource Sharing (CORS)
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
http://www.w3.org/TR/cors/
\end_layout

\end_inset

 is a browser technology specification, which defines ways for a web service
 to provide interfaces for sandboxed scripts coming from a different domain
 under same origin policy.
 The standard works by adding new HTTP headers that allow servers to describe
 the set of origins that are permitted to read that information using a
 web browser.
 
\end_layout

\begin_layout Standard
This specification extends the SOP model in several ways
\begin_inset CommandInset citation
LatexCommand citep
key "SameOrigin"

\end_inset

:
\end_layout

\begin_layout Itemize
A response can include an Access-Control-Allow-Origin header, with the origin
 of where the request originated from as the value, to allow access to the
 resource's contents.
 The user agent validates that the value and origin of where the request
 originated match.
\end_layout

\begin_layout Itemize
User agents can discover via a preflight request whether a cross-origin
 resource is prepared to accept requests, using a non-simple method, from
 a given origin.
 This is again validated by the user agent.
 
\end_layout

\begin_layout Itemize
Server-side applications are enabled to discover that an HTTP request was
 deemed a cross-origin request by the user agent, through the Origin header.
 This extension enables server-side applications to enforce limitations
 (e.g.
 returning nothing) on the cross-origin requests that they are willing to
 service.
\end_layout

\begin_layout Standard
CORS is a modern alternative to the JSONP pattern and an extend to the SOP
 model.
 JSON-P works with the script-tage method , which requests to a remote data
 service location.
 The response (the loaded "JavaScript" content) is the name of a function
 pre-defined on the requesting web page, with the parameter being passed
 to it being the JSON data being requested.
 When the script executes, the function is called and passed the JSON data,
 allowing the requesting page to receive and process the data.
 While JSONP supports only the GET request method, CORS also supports other
 types of HTTP requests.
 Using CORS enables a web programmer to use regular XMLHttpRequest which
 supports better error handling than JSONP.
 On the other hand, JSONP works on legacy browsers which preclude CORS support.
 CORS is supported by most modern web browsers.
\end_layout

\begin_layout Subsubsection
Parameters
\end_layout

\begin_layout Standard
It is possible to provide user inputs when loading a pipe in Yahoo.
 For example the url of the website to search, the number of items to be
 displayed or a location on the map.
 Their website for browsing and running pipes, provides a form section where
 users can see the parameters and enter the values.
 However none of this information in provided when exporting in JSON or
 RSS.
 This is a drawback in functionality as users need to guess or even not
 beware of any input parameters when using the pipe.
 In the implementation a workaround is provided to tackle this problem.
 It's even a practice of the mashup concept itself.
\end_layout

\begin_layout Standard
Mashups can extract content from web sites by a technique known as screen
 scraping.
 In this context, screen scraping denotes the process by which a tool attempts
 to extract information from the content provider by attempting to parse
 the provider's Web pages, which were originally intended for human consumption;
 the pipe information page in this case.
 (e.g.
 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
http://pipes.yahoo.com/pipes/pipe.info?_id=avkEShi32xG_EF6KZVUMqA
\end_layout

\end_inset

) This way semantic data structures representative of the necessary information
 that can be extracted, used and manipulated programmatically.
 Yahoo! Query Language
\begin_inset CommandInset citation
LatexCommand citep
key "YQL"

\end_inset

 is used here in this case.
 It's an expressive SQL-like language that lets you query, filter, and join
 data across Web services.
 With YQL, apps run faster with fewer lines of code and a smaller network
 footprint.
 Yahoo! and other websites across the Internet make much of their structured
 data available to developers, primarily through Web services.
 With YQL, developers can access and shape data across the Internet through
 one simple language, eliminating the need to learn how to call different
 API's or when there is no API available at all.
 To call the YQL Web Service, an application would call an HTTP GET method
 on this parametrised URL.
 The result data can be in XML or JSON format, the latter is used to get
 that information from the pipe info site into the webservice.
\end_layout

\begin_layout Standard
Screen scraping has two primary drawbacks, as also cited in 
\begin_inset Flex CT - auto cross-reference
status collapsed

\begin_layout Plain Layout

sub:Screen-scraping
\end_layout

\end_inset

 The first is that, unlike APIs with interfaces, scraping has no specific
 programmatic contract between content-provider and content-consumer.
 The second issue is the lack of sophisticated, re-usable screen-scraping
 toolkit software.
 The lack of API function to get the Yahoo Pipes parameters via YQL which
 serves as the screen scraping tool.
 The result can be considered as not really an elegant solution, altough
 YQL provides a decent framework and does the job well and delivers a feasible
 solution.
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:Parsing-&-conversion"

\end_inset

Parsing & conversion of data
\end_layout

\begin_layout Subsubsection*
JSON
\end_layout

\begin_layout Standard
JSON (JavaScript Object Notation) is a lightweight data-interchange format.
 It is easy for humans to read and write.
 It is easy for machines to parse and generate.
 It is based on a subset of the JavaScript Programming Language, Standard
 ECMA-262 3rd Edition - December 1999.
 JSON is a text format that is completely language independent but uses
 conventions that are familiar to programmers of the C-family of languages,
 including C, C++, C#, Java, JavaScript, Perl, Python, and many others.
 These properties make JSON an ideal data-interchange language.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Douglas:json"

\end_inset


\end_layout

\begin_layout Standard
JSON is built on two structures:
\end_layout

\begin_layout Enumerate
A collection of name/value pairs.
 In various languages, this is realized as an object, record, struct, dictionary
, hash table, keyed list, or associative array.
 An ordered list of values.
 In most languages, this is realized as an array, vector, list, or sequence.
\end_layout

\begin_layout Enumerate
These are universal data structures.
 Virtually all modern programming languages support them in one form or
 another.
 It makes sense that a data format that is interchangeable with programming
 languages also be based on these structures.
\end_layout

\begin_layout Standard
One of the most important functions in visualisation libraries is the access
 to the data.
 For small projects the libraries have functionality to manually add the
 data.
 For that you have to know a (minimum) of knowledge in programming languages.
 When the amount of data gets larger, this way of working becomes inefficiënt
 and a long work.
 That's why another method of data provision is supported: the JSON format.
 As explained previously, it is a very simple open format to exchange data.
 This way a lot more data can be easily queried and a lot more easilier.
 No more manual adding.
 The data is provided in a structured way.
 But here it is where there arises another problem: which format does the
 data has to be? It seems that this is not such a simple question.
 Altough many libraries provide JSON support, it has to be in the right
 format.
 Otherwise the library can't handle the data.
 Also different libraries have different standard or ways of working with
 the data input.
 There is no general abstraction of using the JSON structured data.
 It seems to be the good choice on one hand, it's not really possible to
 define a standard, that will do no right to the easy use of JSON.
 On the other hand, it makes the implementation more difficult.
 The provided data can have any structure, properties or different types
 of data like strings, numbers for example.
 There is no easy use of the data.
 
\end_layout

\begin_layout Standard
JSONP format is an extension to JavaScript Object Notation (JSON), a lightweight
 data interchange format that is relatively easy to parse and evaluate by
 a JavaScript function.
 This makes data in JSON format relatively easy for a client to handle.
 JSONP appends the name of a local callback function to a JSON object.
 If the specified format is JSONP, a callback function is usually specified
 as a parameter in the request.
\begin_inset CommandInset citation
LatexCommand citep
key "sunclientsidemashups:2007"

\end_inset


\end_layout

\begin_layout Subsubsection*
Data mapping
\end_layout

\begin_layout Standard
Data mapping can be manual or semi-automatic.
 In my project parts of the data are handled in a semi-automatic way.
 JSON doesn't provide any mapping to types.
 In fact it is just is a lightweight text-based open standard designed for
 human-readable data interchange.
 On import, the text is parsed to define a JavaScript object used further
 in the application logic.
 It is a powerful imperative object based language, made popular by its
 widespread use in web pages.
 It supports flexible program development by allowing dynamic addition of
 members to objects.
 Code is embedded directly in web pages, interpreted on page load and dynamicall
y typed.
 If at runtime a field is accessed or method called that does not exist
 then a runtime type error is generated.
 When such errors occur the user is usually presented with an error message.
 
\end_layout

\begin_layout Standard
All the data coming from Yahoo Pipes is had a predefined structure; including
 some general attributes and the most important: a list of items which contains
 the actual data.
 This data gets parsed by the 'parseJSON' JavaScript method and has an optional
 parsing argument: 'reviver'.
 It's a function that filters and transforms the result data.
 The deserialized object is traversed recursively, and the reviver function
 is called for each member of the object in post-order (every object is
 revived after all its members have been revived).
 For each member, the following occurs: 
\end_layout

\begin_layout Itemize
If reviver returns a valid value, the member value is replaced with the
 value returned by reviver.
\end_layout

\begin_layout Itemize
If reviver returns what it received, the structure is not modified.
\end_layout

\begin_layout Itemize
If reviver returns null or undefined, the object member is deleted.
\end_layout

\begin_layout Standard
If a function, prescribes how the value originally produced by parsing is
 transformed, before being returned.
 This function can be very useful because in fact, as stated before the
 output data from JSON is merely a text string and so every type in the
 created JavaScript Object would be of type 'String'.
 With the reviver function, some types can already be converted into the
 right type on parsing the JSON string, e.g.
 the 'pubDate' element.
 Its value is a date, indicating when the item was published and is converted
 to a JavaScript Date object at parsing time.
 If some other elements, like 'year', 'month', 'day', etc..are present, they
 are converted automatically into JavaScript Number Objects.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Maybe here a section about data storage?
\end_layout

\begin_layout Subsection
Testing
\end_layout

\begin_layout Itemize
debugging; getting the import of data right
\end_layout

\begin_layout Itemize
compared the different approaches
\end_layout

\begin_layout Subsection
\begin_inset CommandInset label
LatexCommand label
name "sub:JSON"

\end_inset

JSON
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Visualisation
\end_layout

\begin_layout Standard
For the visualisation of the data, several JavaScript visualisation libraries
 were used, which will be explained in detail below.
 The <script> tag is used to define a client-side script, where this element
 either contains scripting statements or it points to an external script
 file through the src attribute.
 These external scripts can be other JavaScript files on the mashup server
 or a reference to an remote URL which contains the script.
 This latter method is used in this Web service to load the external visualisati
on libraries.
 The required type attribute of the script specifies the MIME type and is
 JavaScript in this case.
\end_layout

\begin_layout Section
User Interface
\end_layout

\begin_layout Standard
The User Interface is implemented as a client-side webpage, containing standard
 HTML elements, extended with AJAX
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
http://en.wikipedia.org/wiki/Ajax_(programming)
\end_layout

\end_inset

.
 Ajax is an acronym for asynchronous JavaScript and XML) and is a group
 of interrelated web development methods used on the client-side to create
 interactive web applications.It is a Web application model rather than a
 specific technology.
 With Ajax, web applications can send data to, and retrieve data from, a
 server asynchronously (in the background) without interfering with the
 display and behavior of the existing page.
 Despite the name, the use of XML is not needed and as in this work, JSON
 is often used instead.
 Ajax consists of standards-based presentation using XHTML and CSS plus
 dynamic display and interaction whereby using the Document Object Model,
 data interchange and manipulation using XML and XSLT, asynchronous data
 retrieval using XMLHttpRequest and JavaScript for binding everything together.
\begin_inset CommandInset citation
LatexCommand citep
key "ibm:thenewbreed"

\end_inset


\end_layout

\begin_layout Standard
When used together, the goal of these technologies is to create a smooth,
 cohesive Web experience for the user by exchanging small amounts of data
 with the content servers rather than reload and re-render the entire page
 after some user action.
 Web mashups can be constructed with Ajax engines from various Ajax toolkits
 and frameworks (such as JQuery, Dojo Toolkit or MooTools), usually implemented
 in JavaScript.
 
\end_layout

\begin_layout Standard
A good example of Ajax use is the Google Maps API, which includes a proprietary
 Ajax engine, and the effect it has on the user experience is powerful:
 it behaves like a truly local application in that there are no scrollbars
 to manipulate or translation arrows that force page reloads.
 The Ajax model of Web development can provide a much richer and more seamless
 user experience than the traditional full-page-refresh.
 In the implementation of the Web service, there is opted for the use of
 Ajax, in particular via standard JavaScript or the use of JQuery to create
 a rich and usable representation of the application logic.
 
\end_layout

\begin_layout Subsection
Visualisation API's
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Google has a good way for inserting data in their charts, trough Google
 Docs, wich works fine with their own service.
 But like we are used to, it protects it's market by recommending their
 own apps.
 So the possibilities for example are to use a Google document, to which
 a chart can be coupled, so the spreadsheet is used as database.
 Another option is to load a JSON object.
 This is more complicated.
 In fact it a more simple thing because the a json object can be very handy
 and easily managed.
 On one hand it seems to be easy to insert the JSON data for using with
 Google chart.
 But that's the trick; the data needs to be in a specific format to be supported.
 Otherwise it won't work.
 So eventually you allready have to know the exact data structure from the
 beginning to use it.
 But can your source work with it or is a conversion necessary.
 Here my library forms a coupling between the data.
 The original data can be any JSON object and the library will convert it
 into the right JSON object which can be used for the visualisation.
 
\end_layout

\begin_layout Plain Layout
The access to data in Javascript.Visualisations need a lot of data.
 But how can we transfer this data in an easy way into Javascript without
 doing it manually.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Google Chart
\end_layout

\begin_layout Standard
Google Chart Tools provide numerous ways to visualize data.
 From simple line charts to complex hierarchical tree maps, the chart galley
 provides a large number of well-designed chart types.
 Populating the data can be done using the provided client- and server-side
 tools.
 Charts are exposed as JavaScript classes.
 Google Chart Tools provides many chart types, although the default appearance
 is best for most situations, a chart can be easily customized to fit the
 look and feel of the website.
 Charts are highly interactive and expose events that enable you to connect
 them to create complex dashboards or other experiences integrated with
 your webpage.
 Charts are rendered using HTML5/SVG technology to provide cross-browser
 compatibility (including VML for older IE versions) and cross platform
 portability to iPhones, iPads and Android.
 No plugins are needed.
 
\begin_inset CommandInset citation
LatexCommand citep
key "api:googlechart"

\end_inset


\end_layout

\begin_layout Standard
All charts are populated with data using a common JavaScript DataTable class.
 Having a common data structure makes it easy to switch between chart types.
 This class exposes methods for sorting, modifying, and filtering data.
 In the implementation this DataTable is populated via JSON and used to
 generate the charts.
 It has it's own structure and therefore the data has to be inserted in
 the right way.
 The original data structure has been mapped to fit the specification for
 the Google DataTable object.
 Once this is done, all the functions to filter or visualise the data are
 envoked directly on this DataTable object.
 It's it a very good way to handle the data for the charts, as the API has
 integrated a lot of functionality.
 
\end_layout

\begin_layout Subsubsection*
Timeline
\end_layout

\begin_layout Standard
Timeline is a free, open-source JavaScript visualisation library to visualize
 temporal information on an interactive drag-able timeline.
 In this project is it used for visualizing a news feed.
 Hereby the data loaded has to be in the RSS format where the necessary
 elements of the feed items have to be provided.
 If the feed items contain the standard title, description and link, they
 can be visualised on the timeline.
 
\end_layout

\begin_layout Standard
This view consists of two time bands: one for the display of the items and
 one for an overview of all the items.
 The time span of both bands can be changed to give a correct representation.
 For example when a feed with recent news items of a particular day is loaded,
 the overview parameter can be set to the day view and gives an overview
 of the day, where the detailed view can be set to a more detailed time
 span to representative data.
\end_layout

\begin_layout Standard
In the user interface there is also a small section for highlighting and
 filtering data.
 The user can insert in the textbox a word to search.
 If the result has been found, it appears in the indicated color.
 This way the UI provides also a filter function to display a more narrow
 data set.
\end_layout

\begin_layout Subsubsection*
d3.js
\end_layout

\begin_layout Standard
This library was first intended to use in the Web Service, but eventually
 didn't make it into the final implementation.
 A first minor research of the API and it's functionality has been done.
 In a later stage of development it seemed that the implementation was not
 trival and only a limited set of functionality would not have contributed
 any value to this work.
\end_layout

\begin_layout Standard
The API has a lot of attractive features and is well designed.
 Here in this subsection you can find a brief description of the functionality.
\end_layout

\begin_layout Standard
D3.js is a small, free JavaScript library for manipulating documents based
 on data.
 D3 allows you to bind arbitrary data to a Document Object Model (DOM),
 and then apply data-driven transformations to the document.
 As a trivial example, you can use D3 to generate a basic HTML table from
 an array of numbers.
 Or, use the same data to create an interactive SVG bar chart with smooth
 transitions and interaction.
\end_layout

\begin_layout Standard
D3 is not a traditional visualization framework.
 Rather than provide a monolithic system with all the features anyone may
 ever need, D3 solves only the crux of the problem: efficient manipulation
 of documents based on data.
 This gives D3 extraordinary flexibility, exposing the full capabilities
 of underlying technologies such as CSS3, HTML5 and SVG.
 It avoids learning a new intermediate proprietary representation.
 With minimal overhead, D3 is extremely fast, supporting large datasets
 and dynamic behaviors for interaction and animation.
 And, for those common needs, D3’s functional style allows code reuse through
 a diverse collection of optional modules.
 
\begin_inset CommandInset citation
LatexCommand citep
key "api:d3.js"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
This is about data and the flow of data.
 It's also about usability.
 Some kind of layer in between to technologies.
 I need to connect the dots.
 In Javascripting you can write libraries.
 What can you do with JavaScript? It a language for scripting and developing
 web applications.
 So users can write code and perform tasks more easily or have tasks automated.
 One type of libraries are visualisation libraries, by which the user can
 create charts, plots, geomaps and all others kinds of interesting visualisation
s.
 Visualisation is a widely and quite vage description.
 I shall explain it some more in detail.
 Mostly it is used when users have some kind of data that they want to represent
 in a different way.
 An important concept in developing applications is that data and visualisation
 should be two different things and also be handled seperatly.
 It's not a good solution to bind a certain type of visualisation hardcoded
 to the data.
 If you then want to have another view on the data, another font or color
 for example, it's hard to change it.
 When you seperate things, the view can be modified and choosen freely.
\end_layout

\begin_layout Plain Layout
So in the first part you have the data, which can contain any type of data:
 text, numbers, relationships, etc..
 The size of the data also matters for the processing quality and speed.
 Large amounts of data are more difficult to handle and take more time,
 which can decrease a good user experience, for example if one has to wait
 to long for results.
 If the visualisation is added up with that, the time increases even more.
 That's a part why performance is important, the performance of the code.
 This means performance of several parts: querying data, updating data,
 creating new data structures and data views.
 This last part is in general what a visualisation library in Javascript
 is doing; it takes a set of data and creates a 'view' on this data in the
 form of a table, a chart or something else.
\end_layout

\begin_layout Plain Layout
Let me now explain where the difficult part comes in this problem: where
 do we get the data? Mostly data is stored in databases of all sorts, online
 or offline.
 The data can be already provided in some sort of form or it can be necessary
 that the data still needs to be accquired.
 So you have two parts in the origin of the data: one, the creation of data
 and two, the handling/usage of the data.
\end_layout

\begin_layout Plain Layout
The source for your data can be retrieved for example from the internet.
 That's were Yahoo Pipes comes in.
 It's a very handy tool to get data from the internet in all forms; web
 content, rss feed items, geolocations, csv-files.
 It is clear that the possibilities are endless, all kinds of data can be
 retrieved from the web.
 In first instance, Yahoo Pipes seems to be used for aggregating or manipulating
 RSS feeds.
 One could think of mainly text and news feeds, but it can reach further
 than that.
\begin_inset Note Note
status open

\begin_layout Plain Layout
Write some more here about RSS, what it is used for.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
CSV files with financial data, a lot of numbers etc..or even XML files containing
 a structured way of data with several caracteristics, maplocations, gps-coordin
ates..There are no limits on the data you can provide.
 This is a very interesting thing, but which makes everything also a lot
 more complex.
 So the input should be handled with care and parsed correctly.
 Yahoo Pipes provides a lot of good things for this.
 It has some nice functionality to handle the data correctly.
 The user than can design it's own mashup or output what they want to do
 with it.
 For example different views, filters etc can be applied on the data.
 It a little like a database where the user can query things etc..Yahoo Pipes
 is a data processor for the web.
\end_layout

\begin_layout Plain Layout
So here's step two.
 Now that we have collected the data, what can we do with it? Like a already
 previously mentioned, Yahoo Pipes can manipulate and filter the data, even
 based on user inputs.
 So you can either just collect data in a central place of go a step further
 by manipulating.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
90% off course > steering
\end_layout

\begin_layout Plain Layout
Focus on the handling of data.
 Less on the user interface.
 Why? It seems more important to have a good data handling, this brings
 on the greatest value.
 Afterwards it is something good to fine tune the user interface.
 This way the library will become more accessibly for less skilled programmers
 who wish to use the visualise data.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Usability
\end_layout

\begin_layout Plain Layout
What is the usability of my solution? Integration into other projects: fork
 it.
 Plus as a starting reference for further research.
\end_layout

\begin_layout Plain Layout
Improvements in my own implementation by going from hard code to a web user
 interface; See for more information 
\end_layout

\begin_layout Itemize
posibility to use the code in your own website; portability
\end_layout

\begin_layout Itemize
User interface for a great overview: viewing data and visualisation + control
 dashboard
\end_layout

\begin_layout Itemize
Clear documentation: for noobs as for more experienced developers
\end_layout

\begin_layout Plain Layout
The first property is the environment’s interface paradigm and target users.
 Mashup tools can support design via different interface/ modeling paradigms,
 such as visual drag-anddrop features, textual editors, or a combination
 of the two.
 The interface can target average Web users, advanced (tech-savvy) users,
 or programmers.
 The interface’s ease of use is the key factor in bringing mashup capability
 to average and advanced Internet users.
\begin_inset CommandInset citation
LatexCommand citep
key "Yu:2008:UMD:1439188.1439257"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Itemize
JavaScript library.
 Provide a JavaScript library of functions that facilitate the use of your
 service.
 Clients can then include the JavaScript library by referencing it in a
 web page on their site.
 Pertinent functions in the JavaScript library should dynamically create
 <script> tags and make JSONP requests.
 As mentioned earlier, dynamically created <script> tags can communicate
 with any domain, so requests for your service from these <script> tags
 avoid the constraints of the browser security sandbox.
 In response, your service returns data in JSONP format.
 When the client receives the response, it calls the callback function specified
 in the JSONP request, passing it a JSON object.
 
\end_layout

\begin_layout Itemize
Cascading Style Sheet (CSS) file.
 Clients can include this file by referencing it in a web page.
 The CSS file enables the client to customize the look and feel of components
 in the web page that display content from your service and to do it without
 changing the code in the page.
 
\end_layout

\begin_layout Itemize
API documentation and examples.
 Document the interface to your service, that is, its API, and provide coding
 examples that demonstrate the use of the API.
 Developers can then use your service by copying a pertinent example into
 their code and modifying it as necessary.
 
\begin_inset CommandInset citation
LatexCommand citep
key "sunclientsidemashups:2007"

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
